<html>

<head>
    <!-- google-site-verification or baidu-site-verification -->
    <meta name="google-site-verification" content="-werZO80S6nK-M6JJZOv-awc-_Qo7Gl_YWWekKq3_rc" /> <!-- http://www.google.com/webmasters/tools/ -->
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- annotation -->
    <!-- <link rel="shortcut icon" href="photos/MyPhoto.ico" />
    <link rel="bookmark" href="photos/MyPhoto.ico" type="image/x-icon"　/> -->
    <title>Ronghao Lin Resume</title>
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="text-align: center;">Ronghao Lin (PhD student at SYSU)</h1>
<p style="text-align: center; font-size: 90%">[ <a href="#bio">Bio</a>,
    <a href="#publications">Publications</a>,
    <a href="#education">Education</a>,
    <a href="#experiences">Experiences</a>,
    <!-- <a href="#teaching">Teaching</a>,  -->
    <a href="#services">Services</a>, 
    <a href="#awards">Awards</a>
    ]
</p>
<hr>
</td>
<td id="layout-content"> 
    <br>
    <table class="imgtable"><tr valign="top">
        <td><img src="photos/BlackCat.jpg" alt="Ronghao Lin" style="width:auto; height:14em" /></td>
        <td align="left">
            <p><span style="font-size: 125%"><b>Ronghao Lin</b></span></p>
            <p>
                Ph.D. student,<br>
                School of Electronics and Information Technology,<br>
                <a href="https://www.sysu.edu.cn/">Sun Yat-sen University</a>.<br>
            </p>
            <p>
                Guangzhou, China<br>
            </p>
            <p>
                Email: linrh7@mail2.sysu.edu.cn<br>
            </p>
            <p>
                [<a href="mailto:linrh7@mail2.sysu.edu.cn">Email</a>,
                <a href="linrh7@mail2.sysu.edu.cn">Google Scholar</a>,
                <a href="https://orcid.org/0000-0003-4530-4529">ORCID</a>,
                <a href="https://github.com/RH-Lin">Github</a>
                <!--<a href="https://www.linkedin.com/in/chenchen-ye/">LinkedIn</a> ,
                <a href="https://twitter.com/chenchenye_ccye">Twitter</a> -->]
            </p>
        </td>
        <td align="right">
            <img src="photos/SYSU-logo.png" alt="SYSU" style="width: auto; height: 6em;" />
            <br>
            <!--<img src="photos/Lab-logo.jpg" alt="Research Lab" style="width: auto; height: 6em;" />-->
        </td>
    </tr></table>

    <h2><hr><br><a name="bio"></a>Brief Bio</h2>
    <div>
        <p>
            Highly-motivated Ph.D. in Information and Communication Engineering with good foundations of computer science, physics, and artificial intelligence. 
            </p>
        <p>
            Research interests: CV&NLP with DL, Multimodal Representation Learning and Generation with MLLM&Diffusion Model, 
            Self-supervised Learning, World Model, Affective Computing, Embodied Intelligence, AI4Science.<br> 
        </p>
    </div>


    <h2><hr><br><a name="publications"></a>Publications</h2>
    <p>(* denotes equal contribution.)</p>
    <div>
        <strong>Preprints:</strong><br><br>
        <!--<ul> 
            <li><p> 
                <b><a href="https://arxiv.org/abs/xxxx">Paper Title</a></b><br>
                <strong>Name1*</strong>, Name2*, Name3<br>
                <em>Preprint 2024</em><br>
                [<a href="https://arxiv.org/pdf/xxxx">Paper</a>]
                [<a href="https://xxxx.github.io">Homepage</a>]
                [<a href="https://github.com/xxxx">Code</a>]
                [<a href="https://drive.google.com/file/d/xxxx">Data</a>]
                [<a href="https://youtu.be/xxxx">Demo Video</a>]
                [<a href="https://colab.research.google.com/drive/xxxx">Demo Notebook</a>]
                [<a href="slides/xxx_slide.pdf">Slides</a>]
            </p></li>
            <br>
        </ul><br> --> 
        <strong>1st Author Publications:</strong><br><br>
        <ul> <!--<ol>-->
            <li><p>
                <b>Adapt and Explore: Multimodal Mixup for Representation Learning</b><br>
                <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>ELSEVIER Information Fusion (INFFUS, JCR Q1, IF 18.6), 2024</em><br>
                [<a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253523005328">Paper</a>]
                [<a href="https://github.com/RH-Lin/m3ixup">Code</a>]
            </p></li>
            <br>
            <li><p>
                <b>MissModal: Increasing Robustness to Missing Modality in Multimodal Sentiment Analysis</b><br>
                <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>MIT Transactions of the Association for Computational Linguistics (TACL, JCR Q1, IF 10.9), 2023</em><br>
                [<a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00628/118797/MissModal-Increasing-Robustness-to-Missing">Paper</a>]
                [<a href="https://github.com/RH-Lin/MissModal">Code</a>]
            </p></li>
            <br>
            <li><p>
                <b>Multi-Task Momentum Distillation for Multimodal Sentiment Analysis</b><br>
                <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Affective Computing (TAFFC, JCR Q1, IF 11.2), 2023</em><br>
                [<a href="https://ieeexplore.ieee.org/abstract/document/10143237">Paper</a>]
                <br>
            </p></li>
            <br>
            <li><p>
                <b>Dynamically Shifting Multimodal Representations via Hybrid-Modal Attention for Multimodal Sentiment Analysis</b><br>
                <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Multimedia (TMM, JCR Q1, IF 7.3), 2023</em><br>
                [<a href="https://ieeexplore.ieee.org/document/10214099">Paper</a>]
                <br>
            </p></li>
            <br>
            <li><p>
                <b>Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis</b><br>
                <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>Findings of the Association for Computational Linguistics: EMNLP 2022 (CCF-B)</em><br>
                [<a href="https://aclanthology.org/2022.findings-emnlp.36/">Paper</a>]
                <br>
            </p></li>
        </ul>
        <details open>
        <summary><strong>Co-Author Publications:</strong></summary>
        <p> 1111111111<br><br> </p>
        </details>
        
        <strong>Co-Author Publications:</strong><br><br>
        <span>
        <ul> <!--<ol>-->
            <li><p>
                <b>Mind the Inconsistent Semantics in Positive Pairs: Semantic Aligning and Multimodal Contrastive Learning for Text-based Pedestrian Search</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Information Forensics and Security (TIFS, JCR Q1, IF 7.2), 2024</em><br>
            </p></li>
            <br>
            <li><p>
                <b>Disentangling Modality and Posture Factors: Memory-Attention and Orthogonal Decomposition for Visible-Infrared Re-Identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS, JCR Q1, IF 10.4), 2024</em><br>
            </p></li>
            <br>
            <li><p>
                <b>Tri-Level Modality-Information Disentanglement for Visible-Infrared Person Re-Identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Multimedia (TMM, JCR Q1, IF 7.3), 2024</em><br>
            </p></li>
            <br>
            <li><p>
                <b>Modality and Camera Factors Bi-Disentanglement for NIR-VIS Object Re-identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Information Forensics and Security (TIFS, JCR Q1, IF 7.2), 2023</em><br>
            </p></li>
            <br>
            <li><p>
                <b>Mask-Aware Pseudo Label Denoising for Unsupervised Vehicle Re-Identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Intelligent Transportation Systems (TITS, JCR Q1, IF 9.6), 2023</em><br>
            </p></li>
            <br>
            <li><p>
                <b>MART: Mask-Aware Reasoning Transformer for Vehicle Re-identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Intelligent Transportation Systems (TITS, JCR Q1, IF 9.6), 2023</em><br>
            </p></li>
            <br>
            <li><p>
                <b>Identity-Unrelated Information Decoupling Model for Vehicle Re-Identification</b><br>
                Zefeng Lu, <strong>Ronghao Lin</strong>, Haifeng Hu<br>
                <em>IEEE Transactions on Intelligent Transportation Systems (TITS, JCR Q1, IF 9.6), 2022</em><br>
            </p></li>
            <br>
        </ul>
        </span><a href="javascript:;" id="btn"> <<<Hide </a>
        <script type="text/javascript">
            //获取元素
            var span = document.querySelector('span');
            var btn = document.querySelector('btn');
            //获取span中的内容
            var str = span.innerText;
            //截取部分内容连接上...
            var sub = str.substring(0,10) + '...';
            //设置开关
            var onoff = true;
            btn.onclick = function(){
            	if(onoff){//判断是true 或 false 前者是收缩状态，后者是展开状态；
            		span.innerText = sub;
            		btn.innerText = '>>> Display';
            	}else{
            		span.innerText = str;
            		btn.innerText = '<<< Hide';
            	}
            	//改变开关的值。
            	onoff = !onoff;
            }
        </script>
    </div>

    <h2><hr><br><a name="experiences"></a>Projects/Research Experiences</h2>
    <div>
        <ul>
            <li><p>
                <b>Successive Master and PhD program</b>, Apr. 2021 - present<br>
                <em>Multimedia Analysis and Intelligence Vision Applications Lab (MAIVA), China</em><br>
                Supervisor: <a href="https://seit.sysu.edu.cn/teacher/HuHaifeng">Haifeng Hu</a><br>
                Topic: Affective Computing Based on Multimodal Understanding and Generation<br>
            </p></li>
            <br>
            <li><p>
                <b>Summer Research Internship/Assistant</b>, Jul. 2023 - Sep. 2023<br>
                <em>HKU-MM Lab (Multimedia Lab), The University of Hongkong, HKSAR.</em><br>
                Supervisor: <a href="http://luoping.me/">Ping Luo</a> <br>
                Topic: Unifying Multimodal Generation and Perception via Energy-based Diffusion
            </p></li>
            <br>
            <li><p>
                <b>Technical Exchange and Project Cooperation</b>, Sep. 2021 - present<br>
                <em>Desay SV Research Institute, China.</em><br>
                Supervisor: <a href="https://seit.sysu.edu.cn/teacher/HuHaifeng">Haifeng Hu</a>, Dean Li Huang <br>
                Project: Dynamic Calibration, Visual SLAM, Autonomous Parking System, AIGC for Driving Scene, and World Models.
            </p></li>
            <br>
            <li><p>
                <b>Software&Hardware Combination Scheme Team in Auto-stereoscopic Display</b>, Mar. 2020 - Jun. 2021<br>
                <em>Midstereo Technology Co. Ltd, China.</em><br>
                Supervisor: <a href="https://oemt.sysu.edu.cn/teacher/573">Prof. Jianying Zhou</a> (Founder&Dean) <br>
                Topic: Research on Detection and Avoidance of Flicker in Auto-stereoscopic Display
            </p></li>
            <br>
            <li><p>
                <b>Undergraduate Scientific Research Project</b>, Sep. 2018 - Sep. 2019<br>
                <em>Institute of High Energy Physics (CAS), China.</em><br>
                Supervisor: <a href="https://www.smooth-sysu.cn/tangjian-page/tangjian.html">Prof. Jian Tang</a> <br>
                Topic: Accelerator Searching for Low-quality Dark Matter Solutions
            </p></li>
        </ul>
    </div>

    <h2><hr><br><a name="education"></a>Education</h2>
    <div>
        <ul>
            <li><p>
                <b>PhD in Information and Communication Engineer &ensp;<em><font color="red">Top 1%</font></em></b><br>
                School of Electronics and Information Technology,Sun Yat-sen University, Guangdong, China.<br>
                Sep. 2021 - Present<br>
            </p></li>
            <br>
            <li><p>
                <b>Bachelor of Science in Opto-electronic Information Science and Engineering &ensp;<em><font color="red">Top 5%</font></em></b><br>
                School of Physics, Sun Yat-sen University, Guangdong, China<br>
                Sep. 2017 - Jun. 2021<br>
            </p></li>
            <br>
            <li><p>
                <b>Minor in Finance &ensp;<em><font color="red">Top 5%</font></em></b><br>
                Lingnan College, Sun Yat-sen University, Guangdong, China<br>
                Sep. 2019 - Feb. 2021<br>
            </p></li>
        </ul>
    </div>

    <!-- <h2><hr><br><a name="teaching"></a>Teaching</h2>
    <div>
        <ul>
            <li><p>
                <b>Teaching Assistant</b> @ NUS<br>
                - <a href="https://cources_website">Introduction of Artificial Intelligence</a>, 2013-2024<br>
                - <a href="https://cources_website">Electronic Technology Comprehensive Design Experiment</a>, 2019-2021<br>
                
            </p></li>
        </ul>
    </div> -->

    <h2><hr><br><a name="services"></a>Services</h2>
    <div>
        <strong>Professinoal:</strong><br><br>
        <ul> 
            <li><p> 
                <b>Invited Journal Reviewer</b>: IEEE Transactions on Affective Computing(TAFFC),
                IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP);
                Elsevier Information Fusion (INFFUS), Neurocomputing (NEUCOM) <br>
            </p></li>
            <li><p> 
                <b>Conference Reviewer</b>: ACL2024 <br>
            </p></li>
        </ul><br>
        <strong>Community:</strong><br><br>
        <ul> <!--<ol>-->
            <li><p>
                Party Branch Secretary, SYSU, 2023-2024 <br>
            </p></li>
            <li><p>
                Commissary in Charge of Organization, SYSU, 2021-2023<br>
            </p></li>
            <li><p>
                Foreign Affairs Volunteer of Municipal Party of Jieyang, Guangdong, China, 2020-2021<br>
            </p></li>
            <li><p>
                Carry out "Volunteer to Countryside" Service for Electrical Maintenance in Qingyuan, Guangdong, China, 2018 <br>
            </p></li>
            <li><p>
                Leader of Appliance Maintenance Team, SYSU, 2018-2020<br>
            </p></li>
        </ul>
    </div>

    <h2><hr><br><a name="awards"></a>Selected Awards</h2>
    <div>
        <ul>
            <li><p>
                SYSU Academic Star (First Session, Individual), SYSU, Dec. 2023 &ensp;<em><font color="red">Top 1%</font></em><br>
            </p></li>
            <li><p>
                Excellent Postgraduate Part-time Counselor (Individual), SYSU, Jun. 2023<br>
            </p></li>
            <li><p>
                1st prize of Excellent Postgraduate Scholarship, SYSU, 2021-2024 &ensp;<em><font color="red">Top 1%</font></em><br>
            </p></li>
            <li><p>
                Excellent Undergraduate Graduation Thesis, 2021 &ensp;<em>(<font color="red">Top 1%</font>)</em><br>
            </p></li>
            <li><p>
                2nd prize of Excellent Undergraduate Scholarship, SYSU, 2019-2021 &ensp;<em><font color="red">Top 1%</font></em><br>
            </p></li>
            <li><p>
                2nd prize of the 7th China University Students Public Relations Plan Contest, China, Sep. 2019 <br>
            </p></li>
        </ul>
    </div>

    <br>
    <hr>

    <p>
        <!-- <br>
        Other Links:[<a href="https://www.linkedin.com/xxx/">LinkedIn</a>,
        <a href="https://twitter.com/xxx">Twitter</a> ] -->
        <br>Last Updated: August 2024.
    </p>
</td>
</tr>
</table>
</body>

</html>
